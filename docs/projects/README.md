---
pageClass: projects-page
---

# Work

Here are some works of mine! :books:

## Projects

<ProjectCard image="/projects/fastspeech.png" hideBorder=true>
**Machine Learning Engineering Intern**

 Advisor: Minchuan Chen, Senior Machine Learning Engineer, Pingan Technology

During the internship, I actively participated in tasks related to speech synthesis. I did extensive research and worked with advanced TTS models like PITS, FastSpeech2, HifiGAN, FastPitch, VITS, Tacotron, and LPCNet. My focus was on improving voice cloning quality, supporting multiple languages, and accommodating multiple speakers. I refined models, fine-tuned synthesis models, and conducted audio quality checks. Achievements include implementing VITS-based speech cloning, Tacotron+lpcnet, and FastSpeech2+HiFiGAN and improved Mean Opinion Score by over 0.2. I plan to enhance audio evaluation and improve naturalness in synthesized speech in the future work.



</ProjectCard>

<ProjectCard image="/projects/eqlens.jpg" hideBorder=true>
**Explanatory Data Visualization Research Project**

 Advisor: Meng Xia, Postdoctoral Faculty, Human-Computer Interaction Institute, CMU

 We hope to explore  teacher behaviors to help improve intelligent tutor systems. We built an interaction interface presenting studentsâ€™ problem-solving processes, including hint-asking behaviors to help teachers understand student process of solving problems.
 Then we conducted a within-subject user study with math teachers to derive data insights for improving intelligent tutors.
 Paper accepted for AIED 2023.


</ProjectCard>

<ProjectCard image="/projects/ctat.jpg" hideBorder=true to="/article/vc/">
[**Human Computer Interaction Intern**](/article/vc/)

Advisor: Vincent Aleven, Professor, Human-Computer Interaction Institute, CMU

 I joined cmu ctat group as summer intern in 2022 summer recommended by my undergraduate tutor. During the job I helped build a web-based intelligent tutoring tool which provides step-wise, personalized and immediate feedback based on a cognitive model for students.
  Specially, I built an editor with formula matcher for student input and bound skills with each interaction

<!-- [pdf] -->

</ProjectCard>

<ProjectCard image="/projects/FFDAugmentor.jpg" hideBorder=true to="/article/nn/">
[**Deep Learning Research Project**](/article/nn/)

Advisor: Yanwei Fu, Professor, School of Data Science, Fudan University

 This was the final project of Deep Learning and Neural Network(DATA130011.01, School of Data Science, Fudan University.). In the project I built a neural network framework for few-shot oracle character recognition problems with my teammate.
 We applied non-rigid transformation as a data augmentation method for our training and reached a significant increase of accuracy through comprehensive experiments.
 We extended the augmentation method to sketch recognition problems.
 Paper accepted for ACCV2022 as the lead author.

<!-- [pdf] -->
[link](https://openaccess.thecvf.com/content/ACCV2022/html/Zhao_FFD_Augmentor_Towards_Few-Shot_Oracle_Character_Recognition_from_Scratch_ACCV_2022_paper.html)
[code](https://github.com/Hide-A-Pumpkin/FFDAugmentor)

</ProjectCard>

<ProjectCard image="/projects/onelabeler.jpg" hideBorder=true to="/article/one/">
[**Data Visualization Research Project**](/article/one/)

  Advisor: Siming Chen, Professor, School of Data Science, Fudan University

 The first formal research experience in my school. I independently researched on 3D point cloud segmentation, I built a system for interactive point cloud labeling combined with default labeling using deep learning method. The system supports annotating autonomous driving data with over 100k points and explores user interaction behavior. I proposed an innovative interactive labeling method using SVM, density-based clustering and Fitts's law. The annotation time was greatly saved under the new method.
 Paper submitted and user censoring for TVCG 2023 as the lead author.


<!-- [pdf] -->



</ProjectCard>

<style lang="stylus">

.projects-page
  background-color #fafbfc
  

</style>